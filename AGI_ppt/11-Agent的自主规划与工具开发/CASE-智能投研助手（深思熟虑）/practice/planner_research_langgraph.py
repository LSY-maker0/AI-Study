"""
planner_research_langgraph - æ·±æ€ç†Ÿè™‘æ™ºèƒ½ä½“ - æ´»åŠ¨ç­–åˆ’åŠ©æ‰‹

Author: lsy
Date: 2026/1/14
"""
import os
import json
from datetime import datetime
from typing import Dict, List, Any, Literal, TypedDict, Optional
from pydantic import BaseModel, Field

from langchain_core.prompts import ChatPromptTemplate
from langchain_community.llms import Tongyi
from langchain_core.output_parsers import JsonOutputParser, StrOutputParser
from langgraph.graph import StateGraph, END

# è®¾ç½®APIå¯†é’¥
DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY")

# åˆ›å»ºLLMå®ä¾‹
llm = Tongyi(model_name="qwen-turbo", dashscope_api_key=DASHSCOPE_API_KEY)

class PlannerState(TypedDict):
    """ç­–åˆ’æ™ºèƒ½ä½“çš„çŠ¶æ€"""
    # è¾“å…¥
    participants: str  # å‚ä¸äººå‘˜
    core_goal: str  # æ ¸å¿ƒç›®æ ‡
    budget: str  # é¢„ç®—é™åˆ¶
    atmosphere: str  # æœŸæœ›æ°›å›´

    # ä¸­é—´çŠ¶æ€
    analysis: Optional[str]  # éœ€æ±‚åˆ†æç»“æœ
    options: Optional[List[Dict]]  # å€™é€‰æ–¹æ¡ˆåˆ—è¡¨
    best_option: Optional[Dict]  # é€‰ä¸­çš„æœ€ä½³æ–¹æ¡ˆ

    # è¾“å‡º
    final_plan: Optional[str]

    # æ§åˆ¶æµ
    current_step: Literal["analyze", "generate", "decide", "plan"]
    error: Optional[str]

# ====== æç¤ºæ¨¡æ¿ä¼˜åŒ– ======

ANALYZE_PROMPT = """ä½ æ˜¯ä¸€ä¸ªæ´»åŠ¨ç­–åˆ’ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹éœ€æ±‚ï¼š
å‚ä¸äººå‘˜: {participants}
æ ¸å¿ƒç›®æ ‡: {core_goal}
é¢„ç®—é™åˆ¶: {budget}
æœŸæœ›æ°›å›´: {atmosphere}

è¯·æ·±å…¥åˆ†æï¼šåœ¨è¿™ä¸ªé¢„ç®—å’Œæ°›å›´ä¸‹ï¼Œå¦‚ä½•æ»¡è¶³æ ¸å¿ƒéœ€æ±‚ï¼Ÿ

è¯·ç”¨ä¸€å¥è¯æ€»ç»“åˆ†æç»“æœï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–è§£é‡Šæˆ–å‰è¨€ã€‚
"""

GENERATE_PROMPT = """ä½ æ˜¯ä¸€ä¸ªæ´»åŠ¨ç‚¹å­ç‹ã€‚æ ¹æ®ä»¥ä¸‹éœ€æ±‚ï¼Œç”Ÿæˆ 3 ä¸ªå®Œå…¨ä¸åŒçš„æ´»åŠ¨æ–¹æ¡ˆã€‚
éœ€æ±‚è¯¦æƒ…ï¼š
å‚ä¸äººå‘˜: {participants}
æ ¸å¿ƒç›®æ ‡: {core_goal}
é¢„ç®—é™åˆ¶: {budget}
æœŸæœ›æ°›å›´: {atmosphere}
éœ€æ±‚åˆ†æï¼š{analysis}

è¯·ç”Ÿæˆ 3 ä¸ªæ–¹æ¡ˆçš„ JSON åˆ—è¡¨ï¼Œæ¯ä¸ªæ–¹æ¡ˆåŒ…å«ï¼š
- id: æ–¹æ¡ˆç¼–å· (1, 2, 3)
- name: æ´»åŠ¨åç§°
- reason: æ¨èç†ç”±
- cost_estimate: é¢„ä¼°èŠ±è´¹

åªè¾“å‡º JSON æ•°ç»„ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
"""

DECIDE_PROMPT = """ä½ æ˜¯å†³ç­–è€…ã€‚æ ¹æ®ç”¨æˆ·çš„æ ¸å¿ƒç›®æ ‡ï¼Œä» 3 ä¸ªæ–¹æ¡ˆä¸­é€‰å‡ºæœ€å¥½çš„ä¸€ä¸ªã€‚
éœ€æ±‚è¯¦æƒ…ï¼š
å‚ä¸äººå‘˜: {participants}
æ ¸å¿ƒç›®æ ‡: {core_goal}
é¢„ç®—é™åˆ¶: {budget}
æœŸæœ›æ°›å›´: {atmosphere}
éœ€æ±‚åˆ†æï¼š{analysis}
å€™é€‰æ–¹æ¡ˆ: {options}

è¯·é€‰æ‹©æœ€ç¬¦åˆ"æ ¸å¿ƒç›®æ ‡"ä¸”åœ¨"é¢„ç®—"èŒƒå›´å†…ä½“éªŒæœ€å¥½çš„æ–¹æ¡ˆã€‚
è¾“å‡ºæ ¼å¼ï¼šJSON {{"selected_id": 1, "reason": "..." }}
"""

PLAN_PROMPT = """ä½ æ˜¯æ‰§è¡Œç§˜ä¹¦ã€‚è¯·æŠŠé€‰å®šçš„æ´»åŠ¨æ–¹æ¡ˆï¼Œç»“åˆç”¨æˆ·çš„åŸå§‹éœ€æ±‚ï¼Œç»†åŒ–æˆå…·ä½“çš„æ‰§è¡Œæ¸…å•ï¼ˆTODO Listï¼‰ã€‚

ã€ç”¨æˆ·åŸå§‹éœ€æ±‚ã€‘
å‚ä¸äººå‘˜: {participants}
æ ¸å¿ƒç›®æ ‡: {core_goal}
é¢„ç®—é™åˆ¶: {budget}
æœŸæœ›æ°›å›´: {atmosphere}
éœ€æ±‚åˆ†æï¼š{analysis}

ã€é€‰å®šçš„æ–¹æ¡ˆã€‘
{best_option}

è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ï¼Œç”ŸæˆåŒ…å«ä»¥ä¸‹å†…å®¹çš„æ¸…å•ï¼š
1. å‡†å¤‡ç‰©å“ï¼ˆå¿…é¡»è€ƒè™‘é¢„ç®—é™åˆ¶ï¼‰
2. å…·ä½“è¡Œç¨‹å®‰æ’ï¼ˆæ—¶é—´è½´å½¢å¼ï¼‰
3. æ³¨æ„äº‹é¡¹

è¯·ç”Ÿæˆä¸€æ®µæ¸…æ™°çš„è‡ªç„¶æ–‡æœ¬è®¡åˆ’ï¼Œè¯­æ°”è¦è´´å¿ƒä¸”ä¸“ä¸šã€‚
"""

# ====== èŠ‚ç‚¹å‡½æ•° ======

def analyze_node(state: PlannerState) -> PlannerState:
    """ç¬¬ä¸€æ­¥ï¼šåŸºäºç»“æ„åŒ–æ•°æ®è¿›è¡Œåˆ†æ"""
    print("1. æ­£åœ¨åŸºäºæ‚¨çš„éœ€æ±‚è¿›è¡Œåˆ†æ...")

    prompt = ChatPromptTemplate.from_template(ANALYZE_PROMPT)
    input_data = {
        "participants": state["participants"],
        "core_goal": state["core_goal"],
        "budget": state["budget"],
        "atmosphere": state["atmosphere"],
    }

    chain = prompt | llm | StrOutputParser()
    result = chain.invoke(input_data)

    print(f"   -> åˆ†æç»“æœ: {result}")

    return {
        **state,
        "analysis": result,
        "current_step": "generate"
    }

def generate_node(state: PlannerState) -> PlannerState:
    """ç¬¬2æ­¥ï¼šç”Ÿæˆæ–¹æ¡ˆ"""
    print("2. æ­£åœ¨å¤´è„‘é£æš´ç”Ÿæˆæ–¹æ¡ˆ...")

    prompt = ChatPromptTemplate.from_template(GENERATE_PROMPT)
    input_data = {
        "participants": state["participants"],
        "core_goal": state["core_goal"],
        "budget": state["budget"],
        "atmosphere": state["atmosphere"],
        "analysis": state["analysis"],
    }

    chain = prompt | llm | JsonOutputParser()
    result = chain.invoke(input_data)

    print(f"   -> ç”Ÿæˆäº† {len(result)} ä¸ªæ–¹æ¡ˆ")
    for opt in result:
        print(f"      - æ–¹æ¡ˆ{opt['id']}: {opt['name']} (ç†ç”±: {opt['reason']}, èŠ±è´¹: {opt['cost_estimate']})")

    return {
        **state,
        "options": result,
        "current_step": "decide"
    }

def decide_node(state: PlannerState) -> PlannerState:
    """ç¬¬3æ­¥ï¼šå†³ç­–æ–¹æ¡ˆ"""
    print("3. æ­£åœ¨è¯„ä¼°å¹¶é€‰æ‹©æœ€ä½³æ–¹æ¡ˆ...")

    prompt = ChatPromptTemplate.from_template(DECIDE_PROMPT)
    input_data = {
        "participants": state["participants"],
        "core_goal": state["core_goal"],
        "budget": state["budget"],
        "atmosphere": state["atmosphere"],
        "analysis": state["analysis"],
        "options": json.dumps(state["options"], ensure_ascii=False),
    }

    chain = prompt | llm | JsonOutputParser()
    result = chain.invoke(input_data)

    selected_id = result["selected_id"]
    best_opt = next((opt for opt in state["options"] if opt["id"] == selected_id), None)

    print(f"   -> å†³å®šé‡‡ç”¨æ–¹æ¡ˆ {selected_id}: {best_opt['name']}")

    return {
        **state,
        "best_option": best_opt,
        "current_step": "plan"
    }

def plan_node(state: PlannerState) -> PlannerState:
    """ç¬¬4æ­¥ï¼šç”Ÿæˆæ‰§è¡Œè®¡åˆ’ï¼ˆä¼˜åŒ–èŠ‚ç‚¹ï¼‰"""
    print("4. æ­£åœ¨ç”Ÿæˆå…·ä½“æ‰§è¡Œè®¡åˆ’...")

    prompt = ChatPromptTemplate.from_template(PLAN_PROMPT)

    # ã€å…³é”®ä¼˜åŒ–ã€‘ï¼šè¿™é‡ŒæŠŠæ‰€æœ‰åŸå§‹éœ€æ±‚éƒ½ä¼ è¿›å»ï¼Œè€Œä¸ä»…ä»…æ˜¯ best_option
    input_data = {
        "participants": state["participants"],
        "core_goal": state["core_goal"],
        "budget": state["budget"],
        "atmosphere": state["atmosphere"],
        "analysis": state["analysis"],
        "best_option": json.dumps(state["best_option"], ensure_ascii=False, indent=2)
    }

    chain = prompt | llm | StrOutputParser()
    final_plan = chain.invoke(input_data)

    return {
        **state,
        "final_plan": final_plan,
        "current_step": "end"
    }

# ====== å·¥ä½œæµæ„å»º ======

def create_planner_agent_workflow():
    """åˆ›å»ºæ·±æ€ç†Ÿè™‘è§„åˆ’æ™ºèƒ½ä½“å·¥ä½œæµå›¾"""
    workflow = StateGraph(PlannerState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("analyze", analyze_node)
    workflow.add_node("generate", generate_node)
    workflow.add_node("decide", decide_node)
    workflow.add_node("plan", plan_node)

    # è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("analyze")

    # è®¾ç½®è¾¹ (çº¿æ€§æµç¨‹)
    workflow.add_edge("analyze", "generate")
    workflow.add_edge("generate", "decide")
    workflow.add_edge("decide", "plan")
    workflow.add_edge("plan", END)

    # ç¼–è¯‘å·¥ä½œæµ
    return workflow.compile()

def run_research_agent(participants, core_goal, budget, atmosphere):
    """è¿è¡Œæ™ºèƒ½ä½“å¹¶è¿”å›ç»“æœ"""
    # åˆ›å»ºå·¥ä½œæµ
    agent = create_planner_agent_workflow()

    # å‡†å¤‡åˆå§‹çŠ¶æ€
    initial_state = {
        "participants": participants,
        "core_goal": core_goal,
        "budget": budget,
        "atmosphere": atmosphere,
        "analysis": None,
        "options": None,
        "best_option": None,
        "final_plan": None,
        "current_step": "analyze",
        "error": None  # è¡¥å…¨å­—æ®µ
    }
    print("LangGraph Mermaidæµç¨‹å›¾ï¼š")
    print(agent.get_graph().draw_mermaid())

    # è¿è¡Œæ™ºèƒ½ä½“
    result = agent.invoke(initial_state)
    return result


def generate_full_report(result: Dict[str, Any], output_path: str):
    """ã€æ–°å¢å‡½æ•°ã€‘å°†æ™ºèƒ½ä½“çš„æ‰€æœ‰è¿‡ç¨‹ç»“æœå†™å…¥æ–‡ä»¶ï¼Œç”Ÿæˆå®Œæ•´æŠ¥å‘Š"""
    report_lines = []
    report_lines.append("=" * 50)
    report_lines.append("         ğŸ“… æ´»åŠ¨ç­–åˆ’å®Œæ•´æŠ¥å‘Š")
    report_lines.append("=" * 50)
    report_lines.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report_lines.append("")

    # 1. åŸå§‹éœ€æ±‚
    report_lines.append("ã€ä¸€ã€ç”¨æˆ·åŸå§‹éœ€æ±‚ã€‘")
    report_lines.append(f"  ğŸ“ å‚ä¸äººå‘˜: {result.get('participants', 'N/A')}")
    report_lines.append(f"  ğŸ¯ æ ¸å¿ƒç›®æ ‡: {result.get('core_goal', 'N/A')}")
    report_lines.append(f"  ğŸ’° é¢„ç®—é™åˆ¶: {result.get('budget', 'N/A')}")
    report_lines.append(f"  ğŸŒŸ æœŸæœ›æ°›å›´: {result.get('atmosphere', 'N/A')}")
    report_lines.append("")

    # 2. éœ€æ±‚åˆ†æ
    report_lines.append("ã€äºŒã€éœ€æ±‚åˆ†æã€‘")
    report_lines.append(f"  {result.get('analysis', 'N/A')}")
    report_lines.append("")

    # 3. å€™é€‰æ–¹æ¡ˆ
    report_lines.append("ã€ä¸‰ã€å€™é€‰æ–¹æ¡ˆåˆ—è¡¨ã€‘")
    options = result.get('options', [])
    if options:
        for opt in options:
            report_lines.append(f"  æ–¹æ¡ˆ {opt['id']}: {opt['name']}")
            report_lines.append(f"    - æ¨èç†ç”±: {opt.get('reason', 'N/A')}")
            report_lines.append(f"    - é¢„ä¼°èŠ±è´¹: {opt.get('cost_estimate', 'N/A')}")
            report_lines.append("")
    else:
        report_lines.append("  (æœªç”Ÿæˆå€™é€‰æ–¹æ¡ˆ)")
        report_lines.append("")

    # 4. å†³ç­–ç»“æœ
    report_lines.append("ã€å››ã€æœ€ç»ˆå†³ç­–ã€‘")
    best_option = result.get('best_option')
    if best_option:
        report_lines.append(f"  âœ… é€‰å®šæ–¹æ¡ˆ: {best_option['name']}")
        report_lines.append(f"  ğŸ’¡ å†³ç­–ç†ç”±: {result.get('decision_reason', 'N/A')}")
        report_lines.append("")
    else:
        report_lines.append("  (æœªé€‰å®šæ–¹æ¡ˆ)")
        report_lines.append("")

    # 5. æ‰§è¡Œè®¡åˆ’
    report_lines.append("ã€äº”ã€æ‰§è¡Œè®¡åˆ’ï¼ˆTODOæ¸…å•ï¼‰ã€‘")
    final_plan = result.get('final_plan')
    if final_plan:
        # å°†é•¿æ®µè½åˆ†è¡Œæ˜¾ç¤ºï¼Œä¿æŒæ ¼å¼
        for line in final_plan.split('\n'):
            report_lines.append(f"  {line}")
    else:
        report_lines.append("  (æœªç”Ÿæˆæ‰§è¡Œè®¡åˆ’)")

    report_lines.append("")
    report_lines.append("=" * 50)
    report_lines.append("         æŠ¥å‘Šç»“æŸ")
    report_lines.append("=" * 50)

    # å†™å…¥æ–‡ä»¶
    report_text = '\n'.join(report_lines)
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(report_text)

    print(f"\nâœ… å®Œæ•´æŠ¥å‘Šå·²ä¿å­˜ä¸º: {output_path}")

# ====== ä¸»ç¨‹åºå…¥å£ ======

if __name__ == "__main__":
    print("=== å‘¨æœ«æ´»åŠ¨ç­–åˆ’åŠ©æ‰‹ ===\n")

    # 1. è·å–ç»“æ„åŒ–æ•°æ®
    participants = input("1. è°å»ï¼Ÿ(ä¾‹å¦‚: å¥³æœ‹å‹ï¼Œä¸€ä¸ªäºº): ")
    core_goal = input("2. å¹²å˜›å»ï¼Ÿ(ä¾‹å¦‚: çºªå¿µæ—¥çº¦ä¼šï¼Œå‘¨æœ«å‡ºè¡Œ): ")
    budget = input("3. é¢„ç®—å¤šå°‘ï¼Ÿ(ä¾‹å¦‚: 500å…ƒï¼Œä¸å·®é’±): ")
    atmosphere = input("4. æƒ³è¦ä»€ä¹ˆæ°›å›´ï¼Ÿ(ä¾‹å¦‚: æµªæ¼«ã€å®‰é™ã€çƒ­é—¹): ")

    try:
        # è¿è¡Œæ™ºèƒ½ä½“
        result = run_research_agent(participants, core_goal, budget, atmosphere)

        # å¤„ç†ç»“æœ
        if result.get("error"):
            print(f"\nå‘ç”Ÿé”™è¯¯: {result['error']}")
        else:
            print("\n=== æœ€ç»ˆç ”ç©¶æŠ¥å‘Š ===\n")
            print(result.get("final_plan", "æœªç”ŸæˆæŠ¥å‘Š"))

            # ä¿å­˜æŠ¥å‘Š
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"research_plan_{timestamp}.txt"
            generate_full_report(result, filename)

            print(f"\næŠ¥å‘Šå·²ä¿å­˜ä¸º: {filename}")

    except Exception as e:
        print(f"\nè¿è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
